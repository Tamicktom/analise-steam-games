{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94bc797",
   "metadata": {},
   "source": [
    "# Preprocessamento\n",
    "\n",
    "Este notebook é para tirar os dados do `.csv` e migrar eles para o Postgres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec96f7",
   "metadata": {},
   "source": [
    "## 1. Preparando o ambiente\n",
    "\n",
    "Antes de iniciarmos a execução do projeto, é fundamental preparar o ambiente Python. Este repositório utiliza Pipenv como gerenciador de dependências e ambientes virtuais. Portanto, recomenda-se que você tenha o Pipenv instalado em sua máquina local.\n",
    "\n",
    "Após confirmar a instalação, execute o seguinte comando na raiz do projeto:\n",
    "\n",
    "```bash\n",
    "pipenv install\n",
    "```\n",
    "\n",
    "Esse comando irá instalar automaticamente todas as dependências necessárias para a reprodução e execução do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91b9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas\n",
    "import sqlalchemy\n",
    "import sqlalchemy.orm as orm\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911c05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamanho do batch para inserção no banco\n",
    "BATCH_SIZE = 2_500\n",
    "\n",
    "# caminho do arquivo corrigido pelo notebook `01-eda.ipynb`\n",
    "CSV_FIXED_PATH = \"./datasets/games_fixed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1e9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove o limite de tamanho de campo do csv\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# mostra todas as colunas do dataframe\n",
    "pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e81cf",
   "metadata": {},
   "source": [
    "## 2. Preparando o PostgreSQL\n",
    "\n",
    "Antes de migrarmos para o PostgreSQL, é necessário preparar o banco de dados e suas tabelas para receber os dados do projeto.\n",
    "\n",
    "Recomendamos utilizar o Docker, pois isso simplifica a criação e execução de um contêiner com PostgreSQL na máquina local. Caso ainda não tenha o Docker instalado, consulte as instruções oficiais disponíveis em: https://docs.docker.com/engine/install/\n",
    "\n",
    "Este repositório inclui um arquivo compose.yml e um arquivo de exemplo .env.example. Para configurar o ambiente:\n",
    "\n",
    "1. Crie um arquivo .env na raiz do projeto.\n",
    "\n",
    "2. Copie o conteúdo de .env.example para dentro do novo arquivo .env.\n",
    "\n",
    "Com isso feito, execute o comando abaixo para inicializar um contêiner com PostgreSQL:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "Esse comando iniciará o banco de dados em segundo plano, permitindo que você continue utilizando o terminal enquanto o serviço é executado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff22dfc",
   "metadata": {},
   "source": [
    "### 2.1 Conectando com o Banco de Dados PostgreSQL\n",
    "\n",
    "Após configurar o ambiente e iniciar o servidor PostgreSQL via Docker, o próximo passo é estabelecer a conexão entre o projeto Python e o banco de dados. Para isso, utilizamos o pacote SQLAlchemy, que fornece uma interface de alto nível para comunicação com bancos relacionais, e o pacote python-dotenv, responsável por carregar as variáveis de ambiente definidas no arquivo `.env`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71158b82",
   "metadata": {},
   "source": [
    "#### 2.1.1. Carregando variáveis de ambiente\n",
    "\n",
    "As credenciais de acesso ao banco (host, porta, usuário, senha e nome do banco) são armazenadas no arquivo `.env`. Isso evita que informações sensíveis fiquem expostas diretamente no código. No início do script, utilizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159dee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96545d0",
   "metadata": {},
   "source": [
    "Esse comando carrega todas as variáveis definidas no `.env` para o ambiente de execução, permitindo acessá-las via `os.getenv()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50e371",
   "metadata": {},
   "source": [
    "#### 2.1.2. Validando as configurações\n",
    "\n",
    "Para garantir que todas as variáveis necessárias foram informadas, o código realiza uma verificação simples. Caso alguma esteja ausente, uma exceção é lançada. Essa etapa evita falhas silenciosas e facilita o diagnóstico de erros de configuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1095bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar variáveis de ambiente\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\")\n",
    "\n",
    "# Verificar se todas as variáveis foram carregadas\n",
    "required_vars = {\n",
    "    \"POSTGRES_HOST\": POSTGRES_HOST,\n",
    "    \"POSTGRES_PORT\": POSTGRES_PORT,\n",
    "    \"POSTGRES_USER\": POSTGRES_USER,\n",
    "    \"POSTGRES_PASSWORD\": POSTGRES_PASSWORD,\n",
    "    \"POSTGRES_DB\": POSTGRES_DB,\n",
    "}\n",
    "\n",
    "missing = [k for k, v in required_vars.items() if not v]\n",
    "if missing:\n",
    "    raise EnvironmentError(f\"Variáveis de ambiente ausentes: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca2ced0",
   "metadata": {},
   "source": [
    "#### 2.1.3. Construindo a URL de conexão\n",
    "\n",
    "Com as variáveis carregadas, construímos a URL de conexão no formato compatível com o driver `psycopg` do SQLAlchemy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5eff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = (\n",
    "    f\"postgresql+psycopg://{POSTGRES_USER}:{POSTGRES_PASSWORD}\"\n",
    "    f\"@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce9e73",
   "metadata": {},
   "source": [
    "Essa URL contém todas as informações necessárias para que o SQLAlchemy saiba como se conectar ao banco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a45f8c",
   "metadata": {},
   "source": [
    "#### 2.1.4. Criando a engine do SQLAlchemy\n",
    "\n",
    "A engine é o objeto central responsável por gerenciar conexões e enviar comandos ao banco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "381ad1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86248bc4",
   "metadata": {},
   "source": [
    "Ela serve como ponto de entrada para operações como consultas, inserções e criação de tabelas.\n",
    "\n",
    "#### 2.1.5. Testando a conexão\n",
    "\n",
    "Por fim, o código tenta abrir uma conexão simples com o banco. Caso seja bem-sucedido, uma mensagem de sucesso é exibida; caso contrário, a exceção é capturada e exibida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc1b604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexão com o banco de dados estabelecida com sucesso!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"✅ Conexão com o banco de dados estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao conectar ao banco de dados: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a9c62",
   "metadata": {},
   "source": [
    "Essa verificação é importante para garantir que o restante do notebook possa interagir com o banco normalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5790636",
   "metadata": {},
   "source": [
    "### 2.2 Modelagem do Banco de Dados com SQLAlchemy\n",
    "\n",
    "A seguir, apresentamos a definição das tabelas e classes que compõem o modelo relacional utilizado neste projeto. A modelagem foi implementada com SQLAlchemy ORM, que permite mapear tabelas e relacionamentos do banco de dados para classes Python, facilitando operações de consulta, inserção e manipulação de dados.\n",
    "\n",
    "#### 2.2.1. Base declarativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38046cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = orm.declarative_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e885cfe",
   "metadata": {},
   "source": [
    "O SQLAlchemy utiliza uma base declarativa como ponto central para registrar todas as classes (models) e metadados das tabelas. Todas as entidades do banco herdam dessa `Base`, o que permite ao framework gerar automaticamente as tabelas no PostgreSQL.\n",
    "\n",
    "#### 2.2.2. Tabelas de associação (relacionamentos M:N)\n",
    "\n",
    "Muitos dos relacionamentos entre jogos (games) e outros elementos (como desenvolvedores, categorias, gêneros, tags e idiomas) são do tipo muitos-para-muitos (M:N). Em um modelo relacional tradicional, esse tipo de relação deve ser representado por tabelas pivô (também chamadas de tabelas de associação ou junction tables).\n",
    "\n",
    "Por exemplo, um jogo pode ter vários desenvolvedores, e um desenvolvedor pode estar associado a vários jogos. Esse padrão se repete para publishers, categorias, gêneros, tags e idiomas.\n",
    "\n",
    "Cada tabela de associação é criada da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b892d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_developer = sqlalchemy.Table(\n",
    "    \"game_developer\",\n",
    "    Base.metadata,\n",
    "    sqlalchemy.Column(\"game_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), primary_key=True),\n",
    "    sqlalchemy.Column(\"developer_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"developers.id\"), primary_key=True)\n",
    ")\n",
    "\n",
    "game_publisher = sqlalchemy.Table(\n",
    "    \"game_publisher\",\n",
    "    Base.metadata,\n",
    "    sqlalchemy.Column(\"game_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), primary_key=True),\n",
    "    sqlalchemy.Column(\"publisher_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"publishers.id\"), primary_key=True)\n",
    ")\n",
    "\n",
    "game_category = sqlalchemy.Table(\n",
    "    \"game_category\",\n",
    "    Base.metadata,\n",
    "    sqlalchemy.Column(\"game_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), primary_key=True),\n",
    "    sqlalchemy.Column(\"category_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"categories.id\"), primary_key=True)\n",
    ")\n",
    "\n",
    "game_genre = sqlalchemy.Table(\n",
    "    \"game_genre\",\n",
    "    Base.metadata,\n",
    "    sqlalchemy.Column(\"game_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), primary_key=True),\n",
    "    sqlalchemy.Column(\"genre_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"genres.id\"), primary_key=True)\n",
    ")\n",
    "\n",
    "game_tag = sqlalchemy.Table(\n",
    "    \"game_tag\",\n",
    "    Base.metadata,\n",
    "    sqlalchemy.Column(\"game_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), primary_key=True),\n",
    "    sqlalchemy.Column(\"tag_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"tags.id\"), primary_key=True)\n",
    ")\n",
    "\n",
    "game_language = sqlalchemy.Table(\n",
    "    \"game_language\",\n",
    "    Base.metadata,\n",
    "    sqlalchemy.Column(\"game_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), primary_key=True),\n",
    "    sqlalchemy.Column(\"language_id\", sqlalchemy.Integer, sqlalchemy.ForeignKey(\"languages.id\"), primary_key=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a16e0d",
   "metadata": {},
   "source": [
    "#### 2.2.3. Características importantes das tabelas pivô:\n",
    "\n",
    "- Não possuem classe ORM própria — pois servem apenas como ligação entre duas entidades.\n",
    "\n",
    "- Cada linha representa um vínculo M:N entre duas tabelas.\n",
    "\n",
    "- Usam chaves estrangeiras para garantir integridade referencial.\n",
    "\n",
    "- A combinação de colunas funciona como chave primária composta.\n",
    "\n",
    "São definidas tabelas equivalentes para publishers, categorias, gêneros, tags e idiomas.\n",
    "\n",
    "#### 2.2.4. Definição dos modelos (tabelas principais)\n",
    "\n",
    "Cada entidade principal do banco de dados (Developer, Publisher, Category, Genre, Tag, Language, Game, entre outras) é representada por uma classe que herda da `Base`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c551d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Developer(Base):\n",
    "    __tablename__ = \"developers\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    name = sqlalchemy.Column(sqlalchemy.Text, nullable=False)\n",
    "\n",
    "    games = orm.relationship(\"Game\", secondary=game_developer, back_populates=\"developers\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_or_create(cls, name, session):\n",
    "        parsed = name.strip().lower()\n",
    "        obj = session.query(cls).filter_by(name=parsed).first()\n",
    "        if obj:\n",
    "            return obj\n",
    "        obj = cls(name=parsed)\n",
    "        session.add(obj)\n",
    "        session.commit()\n",
    "        return obj\n",
    "\n",
    "\n",
    "class Publisher(Base):\n",
    "    __tablename__ = \"publishers\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    name = sqlalchemy.Column(sqlalchemy.Text, nullable=False)\n",
    "\n",
    "    games = orm.relationship(\"Game\", secondary=game_publisher, back_populates=\"publishers\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_or_create(cls, name, session):\n",
    "        parsed = name.strip().lower()\n",
    "        obj = session.query(cls).filter_by(name=parsed).first()\n",
    "        if obj:\n",
    "            return obj\n",
    "        obj = cls(name=parsed)\n",
    "        session.add(obj)\n",
    "        session.commit()\n",
    "        return obj\n",
    "\n",
    "\n",
    "class Category(Base):\n",
    "    __tablename__ = \"categories\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    name = sqlalchemy.Column(sqlalchemy.String(255), nullable=False)\n",
    "\n",
    "    games = orm.relationship(\"Game\", secondary=game_category, back_populates=\"categories\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_or_create(cls, name, session):\n",
    "        parsed = name.strip().lower()\n",
    "        obj = session.query(cls).filter_by(name=parsed).first()\n",
    "        if obj:\n",
    "            return obj\n",
    "        obj = cls(name=parsed)\n",
    "        session.add(obj)\n",
    "        session.commit()\n",
    "        return obj\n",
    "\n",
    "\n",
    "class Genre(Base):\n",
    "    __tablename__ = \"genres\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    name = sqlalchemy.Column(sqlalchemy.String(255), nullable=False)\n",
    "\n",
    "    games = orm.relationship(\"Game\", secondary=game_genre, back_populates=\"genres\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_or_create(cls, name, session):\n",
    "        parsed = name.strip().lower()\n",
    "        obj = session.query(cls).filter_by(name=parsed).first()\n",
    "        if obj:\n",
    "            return obj\n",
    "        obj = cls(name=parsed)\n",
    "        session.add(obj)\n",
    "        session.commit()\n",
    "        return obj\n",
    "\n",
    "\n",
    "class Tag(Base):\n",
    "    __tablename__ = \"tags\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    name = sqlalchemy.Column(sqlalchemy.String(255), nullable=False)\n",
    "\n",
    "    games = orm.relationship(\"Game\", secondary=game_tag, back_populates=\"tags\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_or_create(cls, name, session):\n",
    "        parsed = name.strip().lower()\n",
    "        obj = session.query(cls).filter_by(name=parsed).first()\n",
    "        if obj:\n",
    "            return obj\n",
    "        obj = cls(name=parsed)\n",
    "        session.add(obj)\n",
    "        session.commit()\n",
    "        return obj\n",
    "\n",
    "\n",
    "class Language(Base):\n",
    "    __tablename__ = \"languages\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    name = sqlalchemy.Column(sqlalchemy.String(255), nullable=False)\n",
    "\n",
    "    games = orm.relationship(\"Game\", secondary=game_language, back_populates=\"languages\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_or_create(cls, name, session):\n",
    "        parsed = name.strip().lower()\n",
    "        obj = session.query(cls).filter_by(name=parsed).first()\n",
    "        if obj:\n",
    "            return obj\n",
    "        obj = cls(name=parsed)\n",
    "        session.add(obj)\n",
    "        session.commit()\n",
    "        return obj\n",
    "\n",
    "\n",
    "class Screenshot(Base):\n",
    "    __tablename__ = \"screenshots\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    game_id = sqlalchemy.Column(sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), nullable=False)\n",
    "    screenshot_url = sqlalchemy.Column(sqlalchemy.String(255), nullable=False)\n",
    "\n",
    "\n",
    "class Movie(Base):\n",
    "    __tablename__ = \"movies\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    game_id = sqlalchemy.Column(sqlalchemy.Integer, sqlalchemy.ForeignKey(\"games.id\"), nullable=False)\n",
    "    movie_url = sqlalchemy.Column(sqlalchemy.String(255), nullable=False)\n",
    "\n",
    "\n",
    "class Game(Base):\n",
    "    __tablename__ = \"games\"\n",
    "\n",
    "    id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n",
    "    app_id = sqlalchemy.Column(sqlalchemy.Integer, nullable=False)\n",
    "    name = sqlalchemy.Column(sqlalchemy.Text, nullable=False)\n",
    "    release_date = sqlalchemy.Column(sqlalchemy.Date, nullable=False)\n",
    "    estimated_owners_lower = sqlalchemy.Column(sqlalchemy.Integer, nullable=False)\n",
    "    estimated_owners_upper = sqlalchemy.Column(sqlalchemy.Integer, nullable=False)\n",
    "    peak_ccu = sqlalchemy.Column(sqlalchemy.Integer, nullable=False, default=0)\n",
    "    required_age = sqlalchemy.Column(sqlalchemy.Integer, nullable=False, default=0)\n",
    "    price = sqlalchemy.Column(sqlalchemy.Float, nullable=False, default=0.0)\n",
    "    discount = sqlalchemy.Column(sqlalchemy.Float, nullable=False, default=0.0)\n",
    "    dlc_count = sqlalchemy.Column(sqlalchemy.Integer, nullable=False, default=0)\n",
    "    about_the_game = sqlalchemy.Column(sqlalchemy.Text, nullable=True)\n",
    "    header_image = sqlalchemy.Column(sqlalchemy.Text, nullable=True)\n",
    "    website = sqlalchemy.Column(sqlalchemy.Text, nullable=True)\n",
    "    support_url = sqlalchemy.Column(sqlalchemy.Text, nullable=True)\n",
    "    support_email = sqlalchemy.Column(sqlalchemy.Text, nullable=True)\n",
    "    windows = sqlalchemy.Column(sqlalchemy.Boolean, nullable=False, default=False)\n",
    "    mac = sqlalchemy.Column(sqlalchemy.Boolean, nullable=False, default=False)\n",
    "    linux = sqlalchemy.Column(sqlalchemy.Boolean, nullable=False, default=False)\n",
    "    metacritic_score = sqlalchemy.Column(sqlalchemy.Float, nullable=True)\n",
    "    metacritic_url = sqlalchemy.Column(sqlalchemy.Text, nullable=True)\n",
    "    user_score = sqlalchemy.Column(sqlalchemy.Float, nullable=True)\n",
    "    positive = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    negative = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    score_rank = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    achievements = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    recommendations = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    average_playtime_forever = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    average_playtime_2weeks = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    median_playtime_forever = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "    median_playtime_2weeks = sqlalchemy.Column(sqlalchemy.Integer, nullable=True)\n",
    "\n",
    "    # RELACIONAMENTOS M:N\n",
    "    developers = orm.relationship(\"Developer\", secondary=game_developer, back_populates=\"games\")\n",
    "    publishers = orm.relationship(\"Publisher\", secondary=game_publisher, back_populates=\"games\")\n",
    "    categories = orm.relationship(\"Category\", secondary=game_category, back_populates=\"games\")\n",
    "    genres = orm.relationship(\"Genre\", secondary=game_genre, back_populates=\"games\")\n",
    "    tags = orm.relationship(\"Tag\", secondary=game_tag, back_populates=\"games\")\n",
    "    languages = orm.relationship(\"Language\", secondary=game_language, back_populates=\"games\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c21d84e",
   "metadata": {},
   "source": [
    "#### 2.2.5. Método `get_or_create`\n",
    "\n",
    "As classes também implementam um método utilitário:\n",
    "\n",
    "```python\n",
    "@classmethod\n",
    "def get_or_create(cls, name, session):\n",
    "```\n",
    "\n",
    "Esse método:\n",
    "\n",
    "- Padroniza o nome (ex.: minúsculas).\n",
    "\n",
    "- Verifica se o registro já existe.\n",
    "\n",
    "- Caso não exista, cria um novo.\n",
    "\n",
    "- Garante consistência dos dados ao evitar duplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba171744",
   "metadata": {},
   "source": [
    "### 2.3. Criando as Tabelas no Banco de Dados e Inicializando a Sessão\n",
    "\n",
    "Após definir todos os modelos e tabelas com o SQLAlchemy, o próximo passo é criar a estrutura física dessas tabelas dentro do banco PostgreSQL e preparar uma sessão para realizar operações de leitura e escrita.\n",
    "\n",
    "#### 2.3.1 Criando as tabelas no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db7533f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babfbe9b",
   "metadata": {},
   "source": [
    "O SQLAlchemy mantém, por meio de Base.metadata, um registro completo de todas as classes (models) e tabelas declaradas no projeto. Ao chamar create_all(engine), o framework:\n",
    "\n",
    "- Verifica quais tabelas já existem no banco.\n",
    "\n",
    "- Cria automaticamente apenas as tabelas que ainda não foram criadas.\n",
    "\n",
    "- Garante a criação das tabelas pivô, modelos principais e relacionamentos.\n",
    "\n",
    "Esse comando funciona como uma migração inicial simplificada, útil especialmente em desenvolvimento ou quando o esquema do banco ainda não está sendo gerenciado por uma ferramenta de migração mais avançada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e3b73",
   "metadata": {},
   "source": [
    "#### 2.3.2 Criando a sessão de comunicação com o banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43916bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sqlalchemy.orm.Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d6a05",
   "metadata": {},
   "source": [
    "A sessão (Session) é o componente central do SQLAlchemy ORM para interação com o banco. Ela funciona como:\n",
    "\n",
    "- Uma unidade de trabalho (unit of work), controlando transações.\n",
    "\n",
    "- Um gerenciador de objetos, mantendo instâncias do banco sincronizadas com o Python.\n",
    "\n",
    "- A interface por onde realizamos:\n",
    "\n",
    "  - consultas (session.query(...))\n",
    "\n",
    "  - inserções (session.add(...))\n",
    "\n",
    "  - atualizações\n",
    "\n",
    "  - deleções\n",
    "\n",
    "  - commits e rollbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d49eb25",
   "metadata": {},
   "source": [
    "## 3. Migrar dados\n",
    "\n",
    "A etapa de migração consiste em transformar os dados extraídos do dataset original para o formato necessário no banco PostgreSQL. Neste notebook, a migração é realizada gradualmente para cada entidade relacionada aos jogos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d81c3ee",
   "metadata": {},
   "source": [
    "### 3.1. Carregando o Dataset com Pandas\n",
    "\n",
    "O dataset bruto é carregado utilizando o Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e589be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_dataset = pandas.read_csv(\n",
    "  CSV_FIXED_PATH,\n",
    "  sep=\",\",\n",
    "  quotechar='\"',\n",
    "  quoting=csv.QUOTE_MINIMAL,\n",
    "  engine=\"python\",\n",
    "  encoding=\"utf-8-sig\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e847a2",
   "metadata": {},
   "source": [
    "Esse procedimento lê o arquivo CSV original contendo informações sobre milhares de jogos e suas respectivas categorias, incluindo as tags. Cada coluna será posteriormente transformada para se adequar ao esquema definido no SQLAlchemy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98681231",
   "metadata": {},
   "source": [
    "### 3.2. Processando e Migrando as Tags\n",
    "\n",
    "A coluna Tags do dataset contém listas de tags separadas por vírgulas. Antes de armazená-las, é necessário realizar três etapas:\n",
    "\n",
    "1. Identificar todas as tags únicas existentes no dataset.\n",
    "\n",
    "2. Criar no banco apenas aquelas que ainda não foram registradas.\n",
    "\n",
    "3. Substituir o texto original da coluna por listas de IDs, permitindo relacioná-las aos jogos futuramente.\n",
    "\n",
    "#### 3.2.1 Extração das tags únicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85b9e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega todas as tags da coluna, remove NaN e garante strings\n",
    "tag_column = games_dataset['tags'].dropna().astype(str)\n",
    "\n",
    "unique_tags = set()\n",
    "\n",
    "# extrai tags únicas\n",
    "for tag_string in tag_column:\n",
    "    names = (name.strip().lower() for name in tag_string.split(','))\n",
    "    unique_tags.update(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa0503",
   "metadata": {},
   "source": [
    "Aqui:\n",
    "\n",
    "- Removemos valores ausentes (NaN).\n",
    "\n",
    "- Garantimos que todas as entradas sejam strings.\n",
    "\n",
    "- Dividimos cada linha em múltiplas tags.\n",
    "\n",
    "- Normalizamos (removendo espaços e padronizando para lowercase).\n",
    "\n",
    "- Armazenamos todas as tags únicas em um conjunto (set), que evita duplicações.\n",
    "\n",
    "#### 3.2.2 Verificando tags já existentes no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc55cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_tags = {\n",
    "    t.name.lower()\n",
    "    for t in session.query(Tag).all()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf95f00",
   "metadata": {},
   "source": [
    "Essa consulta evita inserir tags duplicadas, garantindo consistência entre o CSV e o banco.\n",
    "\n",
    "#### 3.2.3 Inserindo apenas tags novas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b44e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = [\n",
    "    Tag(name=tag)\n",
    "    for tag in unique_tags\n",
    "    if tag not in existing_tags\n",
    "]\n",
    "\n",
    "session.bulk_save_objects(new_tags)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336a7dc",
   "metadata": {},
   "source": [
    "**Por que `bulk_save_objects`?**\n",
    "\n",
    "Porque esse método é significativamente mais rápido que inserir objeto por objeto, principalmente quando lidamos com centenas ou milhares de registros.\n",
    "\n",
    "Após a inserção, consultamos todas as tags novamente e criamos um mapa de acesso rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9499e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {\n",
    "    tag.name.lower(): tag.id\n",
    "    for tag in session.query(Tag).all()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b15834",
   "metadata": {},
   "source": [
    "Essa estrutura permite converter o texto das tags em IDs inteiros, que são as chaves estrangeiras necessárias para preencher a tabela de associação `game_tag`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b06c3f",
   "metadata": {},
   "source": [
    "#### 3.2.4 Função auxiliar para mapear nomes → IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09fc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_id(tag_names):\n",
    "    if not isinstance(tag_names, str):\n",
    "        return None\n",
    "    \n",
    "    ids = []\n",
    "    for name in map(str.strip, tag_names.lower().split(',')):\n",
    "        tag_id = tag_map.get(name)\n",
    "        if tag_id is None:\n",
    "            print(f\"Tag {name} não encontrada\")\n",
    "        else:\n",
    "            ids.append(tag_id)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75928edb",
   "metadata": {},
   "source": [
    "Essa função:\n",
    "\n",
    "- Recebe um texto com múltiplas tags.\n",
    "\n",
    "- Normaliza cada tag.\n",
    "\n",
    "- Procura seu ID no dicionário tag_map.\n",
    "\n",
    "- Retorna uma lista contendo todos os IDs encontrados.\n",
    "\n",
    "Essa lista servirá diretamente para construir os relacionamentos M:N posteriormente.\n",
    "\n",
    "#### 3.2.5 Substituindo a coluna original por IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71f3532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_dataset['tags'] = games_dataset['tags'].apply(get_tag_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854c838",
   "metadata": {},
   "source": [
    "Agora, a coluna Tags não contém mais strings, mas listas de IDs, no padrão que será utilizado para inserir corretamente os dados dos jogos e suas relações no banco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46dc99e",
   "metadata": {},
   "source": [
    "### 3.2. Desenvolvedores (developers)\n",
    "\n",
    "O processo de migração dos desenvolvedores segue a mesma lógica apresentada na seção anterior (Migração das Tags). A coluna Developers contém múltiplos valores por jogo, separados por vírgulas, exigindo tratamento semelhante para identificar valores únicos e associá-los aos registros correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e6b2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega todos os developers da coluna\n",
    "developer_column = games_dataset['developers'].dropna().astype(str)\n",
    "\n",
    "# usa set para evitar duplicatas\n",
    "unique_developers = set()\n",
    "\n",
    "# extrai todos os developers únicos\n",
    "for dev_string in developer_column:\n",
    "    names = (name.strip().lower() for name in dev_string.split(','))\n",
    "    unique_developers.update(names)\n",
    "\n",
    "# pega do banco de dados os developers já existentes\n",
    "existing = {\n",
    "    d.name.lower()\n",
    "    for d in session.query(Developer).all()\n",
    "}\n",
    "\n",
    "# filtra apenas os novos\n",
    "new_developers = [\n",
    "    Developer(name=name)\n",
    "    for name in unique_developers\n",
    "    if name not in existing\n",
    "]\n",
    "\n",
    "# Inserção em lote (melhor desempenho do que inserir individualmente)\n",
    "for i in range(0, len(new_developers), BATCH_SIZE):\n",
    "    batch = new_developers[i:i+BATCH_SIZE]\n",
    "    session.add_all(batch)\n",
    "    session.commit()\n",
    "\n",
    "# Cria mapa {nome: id} para facilitar associação futura\n",
    "developer_map = {\n",
    "    dev.name.lower(): dev.id\n",
    "    for dev in session.query(Developer).all()\n",
    "}\n",
    "\n",
    "# Função que converte lista de nomes em lista de IDs\n",
    "def get_developer_id(developer_names):\n",
    "    if not isinstance(developer_names, str):\n",
    "        return None\n",
    "    \n",
    "    ids = []\n",
    "    for name in map(str.strip, developer_names.lower().split(',')):\n",
    "        dev_id = developer_map.get(name)\n",
    "        if dev_id is None:\n",
    "            print(f\"Developer {name} não encontrado\")\n",
    "        else:\n",
    "            ids.append(dev_id)\n",
    "    return ids\n",
    "\n",
    "# Substitui a coluna original pelas listas de IDs\n",
    "games_dataset['developers'] = games_dataset['developers'].apply(get_developer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb88ad",
   "metadata": {},
   "source": [
    "### 3.3. Publicadores (publishers)\n",
    "\n",
    "A migração dos publishers segue a mesma estrutura descrita anteriormente para Tags e Developers. Assim, aplicamos novamente um fluxo semelhante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235d1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega todos os valores da coluna\n",
    "publisher_column = games_dataset['publishers'].dropna().astype(str)\n",
    "\n",
    "unique_publishers = set()\n",
    "\n",
    "# extrai todos os publishers únicos\n",
    "for pub_string in publisher_column:\n",
    "    names = (name.strip().lower() for name in pub_string.split(','))\n",
    "    unique_publishers.update(names)\n",
    "\n",
    "# pega do banco de dados os publishers já existentes\n",
    "existing = {\n",
    "    p.name.lower()\n",
    "    for p in session.query(Publisher).all()\n",
    "}\n",
    "\n",
    "# filtra apenas os novos\n",
    "new_publishers = [\n",
    "    Publisher(name=name)\n",
    "    for name in unique_publishers\n",
    "    if name not in existing\n",
    "]\n",
    "\n",
    "# Inserção em lote (melhor desempenho do que inserir individualmente)\n",
    "for i in range(0, len(new_publishers), BATCH_SIZE):\n",
    "    batch = new_publishers[i:i+BATCH_SIZE]\n",
    "    session.add_all(batch)\n",
    "    session.commit()\n",
    "\n",
    "# Cria mapa {nome: id} para facilitar associação futura\n",
    "publisher_map = {\n",
    "    pub.name.lower(): pub.id\n",
    "    for pub in session.query(Publisher).all()\n",
    "}\n",
    "\n",
    "# Função que converte lista de nomes em lista de IDs\n",
    "def get_publisher_id(publisher_names):\n",
    "    if not isinstance(publisher_names, str):\n",
    "        return None\n",
    "    \n",
    "    ids = []\n",
    "    for name in map(str.strip, publisher_names.lower().split(',')):\n",
    "        pub_id = publisher_map.get(name)\n",
    "        if pub_id is None:\n",
    "            print(f\"Publisher {name} não encontrado\")\n",
    "        else:\n",
    "            ids.append(pub_id)\n",
    "    return ids\n",
    "\n",
    "# Substitui a coluna original pelas listas de IDs\n",
    "games_dataset['publishers'] = games_dataset['publishers'].apply(get_publisher_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e9f46",
   "metadata": {},
   "source": [
    "### 3.4. Categorias (categories)\n",
    "\n",
    "A migração das categorias segue o mesmo padrão já utilizado para Tags, Developers e Publishers. Assim, aplicamos novamente as etapas habituais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73972c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega todos os valores da coluna\n",
    "categories_column = games_dataset['categories'].dropna().astype(str)\n",
    "\n",
    "unique_categories = set()\n",
    "\n",
    "# extrai todos os categories únicos\n",
    "for cat_string in categories_column:\n",
    "    names = (name.strip().lower() for name in cat_string.split(','))\n",
    "    unique_categories.update(names)\n",
    "\n",
    "# pega do banco de dados os categories já existentes\n",
    "existing = {\n",
    "    c.name.lower()\n",
    "    for c in session.query(Category).all()\n",
    "}\n",
    "\n",
    "# filtra apenas os novos\n",
    "new_categories = [\n",
    "    Category(name=name)\n",
    "    for name in unique_categories\n",
    "    if name not in existing\n",
    "]\n",
    "\n",
    "# insere em lote (muito mais rápido do que inserir um a um)\n",
    "for i in range(0, len(new_categories), BATCH_SIZE):\n",
    "    batch = new_categories[i:i+BATCH_SIZE]\n",
    "    session.add_all(batch)\n",
    "    session.commit()\n",
    "\n",
    "category_map = {\n",
    "    cat.name.lower(): cat.id\n",
    "    for cat in session.query(Category).all()\n",
    "}\n",
    "\n",
    "def get_category_id(category_names):\n",
    "    if not isinstance(category_names, str):\n",
    "        return None\n",
    "    \n",
    "    ids = []\n",
    "    for name in map(str.strip, category_names.lower().split(',')):\n",
    "        cat_id = category_map.get(name)\n",
    "        if cat_id is None:\n",
    "            print(f\"Category {name} não encontrada\")\n",
    "        else:\n",
    "            ids.append(cat_id)\n",
    "    return ids\n",
    "\n",
    "# aplica ao dataset\n",
    "games_dataset['categories'] = games_dataset['categories'].apply(get_category_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4dcc84",
   "metadata": {},
   "source": [
    "### 3.5. Generos (genres)\n",
    "\n",
    "> *Como o processo de migração de atributos multivalorados já foi descrito detalhadamente nas seções anteriores, esta etapa apresenta apenas um resumo das operações realizadas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c17e4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega todos os valores da coluna\n",
    "genres_column = games_dataset['genres'].dropna().astype(str)\n",
    "\n",
    "unique_genres = set()\n",
    "\n",
    "# extrai todos os genres únicos\n",
    "for genre_string in genres_column:\n",
    "    names = (name.strip().lower() for name in genre_string.split(','))\n",
    "    unique_genres.update(names)\n",
    "\n",
    "# Pega do banco de dados os genres já existentes\n",
    "existing = {\n",
    "    g.name.lower()\n",
    "    for g in session.query(Genre).all()\n",
    "}\n",
    "\n",
    "# filtra apenas os novos\n",
    "new_genres = [\n",
    "    Genre(name=name)\n",
    "    for name in unique_genres\n",
    "    if name not in existing\n",
    "]\n",
    "\n",
    "# insere em lote (muito mais rápido do que inserir um a um)\n",
    "for i in range(0, len(new_genres), BATCH_SIZE):\n",
    "    batch = new_genres[i:i+BATCH_SIZE]\n",
    "    session.add_all(batch)\n",
    "    session.commit()\n",
    "\n",
    "genre_map = {\n",
    "    genre.name.lower(): genre.id\n",
    "    for genre in session.query(Genre).all()\n",
    "}\n",
    "\n",
    "def get_genre_id(genre_names):\n",
    "    if not isinstance(genre_names, str):\n",
    "        return None\n",
    "    \n",
    "    ids = []\n",
    "    for name in map(str.strip, genre_names.lower().split(',')):\n",
    "        genre_id = genre_map.get(name)\n",
    "        if genre_id is None:\n",
    "            print(f\"Genre {name} não encontrado\")\n",
    "        else:\n",
    "            ids.append(genre_id)\n",
    "    return ids\n",
    "\n",
    "# aplica ao dataset\n",
    "games_dataset['genres'] = games_dataset['genres'].apply(get_genre_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5c834",
   "metadata": {},
   "source": [
    "### 3.6. Linguagens\n",
    "\n",
    "Diferentemente dos atributos anteriores, a migração das linguagens requer um processamento muito mais elaborado. No dataset da Steam, a coluna Supported languages apresenta dados altamente inconsistentes, contendo:\n",
    "\n",
    "- listas malformadas (com aspas quebradas, colchetes incompletos, mistura de ' e \"),\n",
    "\n",
    "- HTML embutido (`<br>`, `<strong>`, etc.),\n",
    "\n",
    "- marcações BBCode (`[b]`, `[i]`),\n",
    "\n",
    "- caracteres estranhos (&lt, &gt, &amp),\n",
    "\n",
    "- idiomas concatenados sem separação clara,\n",
    "\n",
    "- variantes inconsistentes de nomes de idiomas (\"Chinese Simplified Text Only\" → \"simplified chinese\").\n",
    "\n",
    "Por isso, o processo foi dividido em diversas etapas de limpeza e normalização antes da migração propriamente dita.\n",
    "\n",
    "#### 3.6.1 Correção estrutural de listas malformadas\n",
    "\n",
    "Algumas entradas vêm com formato próximo de JSON, mas inválido:\n",
    "\n",
    "```json\n",
    "[\"English, French, German]\n",
    "['Portuguese', 'Spanish']\n",
    "[English, Japanese]\n",
    "```\n",
    "\n",
    "A função `safe_parse_languages` executa várias estratégias:\n",
    "\n",
    "1. Tentar interpretar a string como JSON válida.\n",
    "\n",
    "2. Tentar o ast.literal_eval, que aceita sintaxes Python-like.\n",
    "\n",
    "3. Corrigir manualmente itens quebrados:\n",
    "\n",
    "  1. substituir aspas simples → duplas,\n",
    "\n",
    "  2. colocar aspas em itens ausentes,\n",
    "\n",
    "  3. ajustar colchetes mal formados.\n",
    "\n",
    "6. Repetir a tentativa de JSON.\n",
    "\n",
    "7. Caso ainda falhe, utilizar fallback simples: dividir por vírgulas.\n",
    "\n",
    "O objetivo é garantir que cada entrada seja transformada em uma lista de strings representando idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b16cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_brackets(m):\n",
    "    items = m.group(1).split(\",\")\n",
    "    items = [f'\"{i.strip().strip(\"\\\"\")}\"' for i in items]\n",
    "    return \"[\" + \",\".join(items) + \"]\"\n",
    "\n",
    "def safe_parse_languages(s):\n",
    "    original = s.strip()\n",
    "\n",
    "    # 1. Tentar JSON direto (apenas se começar com [)\n",
    "    if original.startswith(\"[\"):\n",
    "        try:\n",
    "            return json.loads(original)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 2. Tentar literal_eval direto\n",
    "    try:\n",
    "        return ast.literal_eval(original)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 3. Tentar corrigir strings malformadas\n",
    "    fixed = original\n",
    "\n",
    "    # 3.1 Trocar aspas simples por duplas\n",
    "    fixed = fixed.replace(\"'\", '\"')\n",
    "\n",
    "    # 3.2 Garantir que itens sem aspas fiquem entre aspas\n",
    "    # ex: K\"iche\" -> \"K\\\"iche\\\"\"\n",
    "    fixed = re.sub(r'(\\w+)\"', r'\"\\1\"', fixed)\n",
    "\n",
    "    # 3.3 Garantir que itens isolados fiquem entre aspas\n",
    "    # ex: [English, French] → [\"English\", \"French\"]\n",
    "    fixed = re.sub(r\"\\[(.*?)\\]\", fix_brackets, fixed)\n",
    "\n",
    "    # 4. Tentar JSON novamente após correções\n",
    "    try:\n",
    "        return json.loads(fixed)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 5. Fallback manual — remove colchetes e divide por vírgula\n",
    "    fallback = original.strip(\"[]\").split(\",\")\n",
    "    fallback = [x.strip().strip('\"').strip(\"'\") for x in fallback]\n",
    "    return fallback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964806ce",
   "metadata": {},
   "source": [
    "#### 3.6.2. Limpeza profunda de cada nome de idioma\n",
    "\n",
    "A função clean_language aplica um pipeline completo de normalização:\n",
    "\n",
    "1. Remoção de sujeiras estruturais\n",
    "\n",
    "  - decodificação de HTML: `&amp;`, `&gt;`, etc.\n",
    "\n",
    "  - remoção de tags HTML (`<br>`) e BBCode (`[b]`, `[i]`).\n",
    "\n",
    "  - remoção de símbolos no início e fim.\n",
    "\n",
    "  - substituição de quebras de linha por vírgulas.\n",
    "\n",
    "2. Separação de itens grudados\n",
    "\n",
    "Algumas entradas juntam idiomas:\n",
    "\n",
    "```arduino\n",
    "\"english dutch english\"\n",
    "```\n",
    "\n",
    "ou\n",
    "\n",
    "```arduino\n",
    "\"english|german\"  \n",
    "\"japanese/french\"\n",
    "```\n",
    "\n",
    "A função divide esses casos usando `,` `|` `;` `/` como delimitadores.\n",
    "\n",
    "3. Normalização textual\n",
    "\n",
    "- conversão para lowercase,\n",
    "\n",
    "- limpeza de duplicações internas (“english english” → “english”),\n",
    "\n",
    "- normalização Unicode (NFKC) para corrigir acentos,\n",
    "\n",
    "- correções específicas (\"simplified chinese text only\").\n",
    "\n",
    "4. Tratamento de casos especiais\n",
    "\n",
    "- linguagens com apóstrofo preservado (“k'iche'”),\n",
    "\n",
    "- idiomas com parênteses mal formados,\n",
    "\n",
    "- remoção de hashtags e lixo residual.\n",
    "\n",
    "Ao final, cada entrada retorna uma lista de idiomas devidamente normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1d4d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_language(raw):\n",
    "    if not isinstance(raw, str):\n",
    "        return []\n",
    "\n",
    "    # ---- 1) Decode de HTML entities ----\n",
    "    text = html.unescape(raw)\n",
    "\n",
    "    # ---- 2) Remover tags HTML e BBCode ----\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    text = re.sub(r'\\[/?[a-zA-Z0-9]+\\]', '', text)\n",
    "\n",
    "    # ---- 3) Trocar quebras de linha por vírgula ----\n",
    "    text = text.replace(\"\\r\", \",\").replace(\"\\n\", \",\")\n",
    "\n",
    "    # ---- 4) Separar itens que vêm grudados ----\n",
    "    parts = re.split(r'[,\\|;/]+', text)\n",
    "\n",
    "    cleaned = []\n",
    "\n",
    "    for item in parts:\n",
    "        item = item.strip().lower()\n",
    "\n",
    "        if not item:\n",
    "            continue\n",
    "\n",
    "        # Remover hashtags (#lang_français)\n",
    "        if item.startswith(\"#\"):\n",
    "            continue\n",
    "\n",
    "        # Remover sobras de HTML mal formadas (lt, gt, amp)\n",
    "        item = re.sub(r'\\b(lt|gt|amp|strong)\\b', '', item)\n",
    "        item = item.replace(\"&lt\", \"\").replace(\"&gt\", \"\").replace(\"&amp\", \"\")\n",
    "\n",
    "        # Remover símbolos no começo/fim\n",
    "        item = re.sub(r'^[^a-z0-9]+|[^a-z0-9]+$', '', item)\n",
    "\n",
    "        # Normalizar Unicode (corrige francês → français)\n",
    "        item = unicodedata.normalize(\"NFKC\", item)\n",
    "\n",
    "        # Recolocar idiomas compostos comuns\n",
    "        item = item.replace(\"simplified chinese text only\", \"simplified chinese\")\n",
    "        item = item.replace(\"traditional chinese text only\", \"traditional chinese\")\n",
    "\n",
    "        # Remover duplicações internas\n",
    "        item = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', item)\n",
    "\n",
    "        # Tratar casos como english dutch english\n",
    "        words = item.split()\n",
    "        if len(words) > 1 and all(w.isalpha() for w in words):\n",
    "            # Se for uma sequência de idiomas sem vírgula, quebrar\n",
    "            for w in words:\n",
    "                cleaned.append(w)\n",
    "            continue\n",
    "\n",
    "        # Arrumar k'iche (sem remover apóstrofo)\n",
    "        if \"k'iche\" in item:\n",
    "            item = \"k'iche'\"\n",
    "\n",
    "        # Arrumar idiomas que ficaram sem ')'\n",
    "        if \"(\" in item and \")\" not in item:\n",
    "            item += \")\"  \n",
    "\n",
    "        # Descartar se ficou vazio\n",
    "        item = item.strip()\n",
    "        if item:\n",
    "            cleaned.append(item)\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f666df",
   "metadata": {},
   "source": [
    "#### 3.6.3. Extração das linguagens únicas\n",
    "\n",
    "Depois de aplicar safe_parse_languages + clean_language, construímos um conjunto de linguagens únicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88a6cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_languages = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d10ced",
   "metadata": {},
   "source": [
    "Este conjunto agora contém apenas idiomas limpos, padronizados e coerentes.\n",
    "\n",
    "#### 3.6.4. Inserção das linguagens no banco\n",
    "\n",
    "Assim como nas seções anteriores, consultamos linguagens já existentes no banco e inserimos apenas as novas usando batches (`BATCH_SIZE`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0154d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_column = games_dataset['supported_languages'].dropna().astype(str)\n",
    "\n",
    "for lang_string in languages_column:\n",
    "    lang_list = safe_parse_languages(lang_string)\n",
    "\n",
    "    for name in lang_list:\n",
    "        for cleaned in clean_language(name):\n",
    "            if cleaned:\n",
    "                unique_languages.add(cleaned)\n",
    "\n",
    "sorted_unique_languages = sorted(unique_languages)\n",
    "\n",
    "# pega do banco de dados os languages já existentes\n",
    "existing = {\n",
    "    l.name.lower()\n",
    "    for l in session.query(Language).all()\n",
    "}\n",
    "\n",
    "# filtra apenas os novos\n",
    "new_languages = [\n",
    "    Language(name=name)\n",
    "    for name in unique_languages\n",
    "    if name not in existing\n",
    "]\n",
    "\n",
    "# insere em lote (muito mais rápido do que inserir um a um)\n",
    "for i in range(0, len(new_languages), BATCH_SIZE):\n",
    "    batch = new_languages[i:i+BATCH_SIZE]\n",
    "    session.add_all(batch)\n",
    "    session.commit()\n",
    "\n",
    "language_map = {\n",
    "    language.name.lower(): language.id\n",
    "    for language in session.query(Language).all()\n",
    "}\n",
    "\n",
    "def get_language_id(language_names):\n",
    "    if not isinstance(language_names, str):\n",
    "        return None\n",
    "    \n",
    "    ids = []\n",
    "    # nome das linguagens estão muito sujos no dataset, então precisamos limpar antes de aplicar o map\n",
    "    lang_list = safe_parse_languages(language_names)\n",
    "    for name in lang_list:\n",
    "        for cleaned in clean_language(name):\n",
    "            if cleaned:\n",
    "                lang_id = language_map.get(cleaned)\n",
    "                if lang_id is None:\n",
    "                    print(f\"Language {cleaned} not found\")\n",
    "                else:\n",
    "                    ids.append(lang_id)\n",
    "    return ids\n",
    "\n",
    "games_dataset['supported_languages'] = games_dataset['supported_languages'].apply(get_language_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8dc508",
   "metadata": {},
   "source": [
    "### 3.7. Migração dos Jogos (Games) para o Banco de Dados\n",
    "\n",
    "A migração dos jogos representa a etapa central deste pipeline, pois envolve transformar uma grande quantidade de atributos heterogêneos do dataset da Steam em registros consistentes no modelo relacional. Cada linha do dataset é convertida em uma instância da classe Game, que posteriormente será persistida no banco.\n",
    "\n",
    "Como o dataset original apresenta inconsistências estruturais, valores faltantes, formatações variadas e campos semipreenchidos, o processo de conversão precisa ser feito com cuidado para garantir integridade dos dados.\n",
    "\n",
    "#### 3.7.1 Processamento de campos que exigem transformação\n",
    "\n",
    "**Conversão da faixa de Estimated owners**\n",
    "\n",
    "O dataset traz estimativas de jogadores em formato textual:\n",
    "\n",
    "- `\"1000000 - 2000000\"`\n",
    "\n",
    "- `\"0 - 1000\"`\n",
    "\n",
    "- `\"5000000\"` (caso incompleto)\n",
    "\n",
    "- `\" - 1000\"` ou `\"1000000 - \"` (valor ausente)\n",
    "\n",
    "A função `get_estimated_owners()` separa a string em valor mínimo e máximo, normaliza campos vazios para `0`, converte ambos os valores para `int` e retorna a tupla `(lower, upper)`.\n",
    "\n",
    "Isso permite registrar a faixa estimada como dois campos inteiros no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73db42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_owners(estimated_owners):\n",
    "    # break the string into lower and upper\n",
    "    lower, upper = estimated_owners.split('-')\n",
    "    lower = lower.strip()\n",
    "    upper = upper.strip()\n",
    "\n",
    "    if lower == '':\n",
    "        lower = 0\n",
    "    if upper == '':\n",
    "        upper = 0\n",
    "\n",
    "    return int(lower), int(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8dc75",
   "metadata": {},
   "source": [
    "**Padronização das datas (Release date)**\n",
    "\n",
    "A Steam fornece datas em mais de um formato, por exemplo:\n",
    "\n",
    "- `\"Aug 12, 2022\"`\n",
    "\n",
    "- `\"Aug 2023\"`\n",
    "\n",
    "- `\"Coming soon\"`\n",
    "\n",
    "A função `parse_steam_date()` tenta converter datas completas `(\"%b %d, %Y\")`, converter datas apenas com mês e ano `(\"%b %Y\")` e retornar None caso não seja possível interpretar a data.\n",
    "\n",
    "Assim, mantemos coerência nos tipos, armazenando valores inválidos como NULL no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed48e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_steam_date(s):\n",
    "    s = s.strip()\n",
    "\n",
    "    if not s or s.lower() == \"coming soon\":\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return datetime.strptime(s, \"%b %d, %Y\").date()\n",
    "    except ValueError:\n",
    "        # Steam às vezes usa formatos diferentes, exemplo: \"Aug 2023\"\n",
    "        try:\n",
    "            return datetime.strptime(s, \"%b %Y\").date()\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c937ef",
   "metadata": {},
   "source": [
    "#### 3.7.2 Construção do objeto Game\n",
    "\n",
    "Vários campos do dataset podem estar vazios, como:\n",
    "\n",
    "- descrição do jogo,\n",
    "\n",
    "- imagem de cabeçalho,\n",
    "\n",
    "- website,\n",
    "\n",
    "- URL de suporte,\n",
    "\n",
    "- e-mail de suporte,\n",
    "\n",
    "- metacritic score,\n",
    "\n",
    "- score rank.\n",
    "\n",
    "Como strings vazias ou `\"nan\"` não são adequadas para um banco relacional, aplicamos esta regra:\n",
    "\n",
    "- Se o valor estiver vazio, for a string `\"nan\"` ou identificado como `NaN` pelo Pandas, substituímos por `None`.\n",
    "\n",
    "Essa padronização melhora robustez e evita inconsistências nos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7785395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para cada linha do dataset, cria um novo jogo no postgres\n",
    "database_games = []\n",
    "for index, row in games_dataset.iterrows():\n",
    "    id = row['appid']\n",
    "    name = row['name']\n",
    "\n",
    "    # converte a data de lançamento para o formato date\n",
    "    release_date = parse_steam_date(row['release_date'])\n",
    "\n",
    "    estimated_owners = row['estimated_owners']\n",
    "    estimated_owners_lower, estimated_owners_upper = get_estimated_owners(estimated_owners)\n",
    "    peak_ccu = row['peak_ccu']\n",
    "    required_age = row['required_age']\n",
    "    price = row['price']\n",
    "    discount = row['discount']\n",
    "    dlc_count = row['dlc_count']\n",
    "\n",
    "    # se about_the_game estiver vazio, define como None\n",
    "    about_the_game = row['about_the_game']\n",
    "    if about_the_game == '' or about_the_game == 'nan' or pandas.isna(about_the_game):\n",
    "        about_the_game = None\n",
    "\n",
    "    # se header_image estiver vazio, define como None\n",
    "    header_image = row['header_image']\n",
    "    if header_image == '' or header_image == 'nan' or pandas.isna(header_image):\n",
    "        header_image = None\n",
    "\n",
    "    # se website estiver vazio, define como None\n",
    "    website = row['website']\n",
    "    if website == '' or website == 'nan' or pandas.isna(website):\n",
    "        website = None\n",
    "\n",
    "    # se support_url estiver vazio, define como None\n",
    "    support_url = row['support_url']\n",
    "    if support_url == '' or support_url == 'nan' or pandas.isna(support_url):\n",
    "        support_url = None\n",
    "\n",
    "    # se support_email estiver vazio, define como None\n",
    "    support_email = row['support_email']\n",
    "    if support_email == '' or support_email == 'nan' or pandas.isna(support_email):\n",
    "        support_email = None\n",
    "\n",
    "    windows = row['windows']\n",
    "    mac = row['mac']\n",
    "    linux = row['linux']\n",
    "\n",
    "    # se metacritic_score estiver vazio, define como None\n",
    "    metacritic_score = row['metacritic_score']\n",
    "    if metacritic_score == '' or metacritic_score == 'nan' or pandas.isna(metacritic_score):\n",
    "        metacritic_score = None\n",
    "\n",
    "    # se metacritic_url estiver vazio, define como None\n",
    "    metacritic_url = row['metacritic_url']\n",
    "    if metacritic_url == '' or metacritic_url == 'nan' or pandas.isna(metacritic_url):\n",
    "        metacritic_url = None\n",
    "\n",
    "    user_score = row['user_score']\n",
    "    positive = row['positive']\n",
    "    negative = row['negative']\n",
    "\n",
    "    # se score_rank estiver vazio, define como None\n",
    "    score_rank = row['score_rank']\n",
    "    if score_rank == '' or score_rank == 'nan' or pandas.isna(score_rank):\n",
    "        score_rank = None\n",
    "\n",
    "    achievements = row['achievements']\n",
    "    recommendations = row['recommendations']\n",
    "    average_playtime_forever = row['average_playtime_forever']\n",
    "    average_playtime_2weeks = row['average_playtime_two_weeks']\n",
    "    median_playtime_forever = row['median_playtime_forever']\n",
    "    median_playtime_2weeks = row['median_playtime_two_weeks']\n",
    "\n",
    "    game = Game(\n",
    "        app_id=id,\n",
    "        name=name,\n",
    "        release_date=release_date,\n",
    "        estimated_owners_lower=estimated_owners_lower,\n",
    "        estimated_owners_upper=estimated_owners_upper,\n",
    "        peak_ccu=peak_ccu,\n",
    "        required_age=required_age,\n",
    "        price=price,\n",
    "        discount=discount,\n",
    "        dlc_count=dlc_count,\n",
    "        about_the_game=about_the_game,\n",
    "        header_image=header_image,\n",
    "        website=website,\n",
    "        support_url=support_url,\n",
    "        support_email=support_email,\n",
    "        windows=windows,\n",
    "        mac=mac,\n",
    "        linux=linux,\n",
    "        metacritic_score=metacritic_score,\n",
    "        metacritic_url=metacritic_url,\n",
    "        user_score=user_score,\n",
    "        positive=positive,\n",
    "        negative=negative,\n",
    "        score_rank=score_rank,\n",
    "        achievements=achievements,\n",
    "        recommendations=recommendations,\n",
    "        average_playtime_forever=average_playtime_forever,\n",
    "        average_playtime_2weeks=average_playtime_2weeks,\n",
    "        median_playtime_forever=median_playtime_forever,\n",
    "        median_playtime_2weeks=median_playtime_2weeks,\n",
    "    )\n",
    "\n",
    "    database_games.append(game)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d0325",
   "metadata": {},
   "source": [
    "#### 3.7.3 Inserção em lote no banco\n",
    "\n",
    "A quantidade de jogos no dataset pode ser alta (dezenas de milhares). Por isso, a inserção é feita em batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dc1a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insere em lotes\n",
    "for i in range(0, len(database_games), BATCH_SIZE):\n",
    "    batch = database_games[i:i+BATCH_SIZE]\n",
    "    session.add_all(batch)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0c1a9",
   "metadata": {},
   "source": [
    "### 3.8. Vinculação dos jogos com atributos\n",
    "\n",
    "Após inserir todas as entidades principais (Games, Developers, Publishers, Genres, Categories, Tags, Languages) no banco de dados, o próximo passo consiste em criar as relações muitos-para-muitos (M:N) entre os jogos e seus respectivos atributos.\n",
    "\n",
    "Essas relações são representadas pelas tabelas de associação (association tables) criadas no modelo ORM, como `game_developer`, `game_publisher`, `game_genre`, etc.\n",
    "\n",
    "A seguir, apresentamos o processo para vincular jogos a desenvolvedores, que serve como modelo geral para as demais associações.\n",
    "\n",
    "#### 3.8.1 Vinculando Jogos e Desenvolvedores\n",
    "\n",
    "Cada jogo pode ter um ou mais desenvolvedores, e cada desenvolvedor pode ter contribuído para vários jogos. Isso caracteriza uma relação M:N, implementada pela tabela intermediária `game_developer`.\n",
    "\n",
    "O processo de vinculação envolve duas etapas fundamentais:\n",
    "\n",
    "1. Carregar os dados existentes do banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bd3c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar all developers e games\n",
    "developers = {d.id: d for d in session.query(Developer).all()}\n",
    "games = {g.app_id: g for g in session.query(Game).all()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7a561",
   "metadata": {},
   "source": [
    "Também carregamos todos os pares já presentes na tabela de associação. Isso evita a criação de vínculos duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74faf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (game_id, developer_id)\n",
    "existing_pairs = set()\n",
    "\n",
    "# tabela de associação\n",
    "association_table = Game.__table__.metadata.tables[\"game_developer\"]\n",
    "\n",
    "# carrega os pares já existentes no banco\n",
    "rows = session.execute(association_table.select())\n",
    "for game_id, developer_id in rows:\n",
    "    existing_pairs.add((game_id, developer_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d721f75",
   "metadata": {},
   "source": [
    "2. Identificar os relacionamentos que precisam ser criados e inserção em lote dos novos pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b17187b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "total_inserted = 0\n",
    "\n",
    "# percorrer o dataset e criar os pares\n",
    "for row in games_dataset.itertuples():\n",
    "    game = games.get(row.appid)\n",
    "    if not game or not isinstance(row.developers, list):\n",
    "        continue\n",
    "\n",
    "    for dev_id in row.developers:\n",
    "        if dev_id not in developers:\n",
    "            continue\n",
    "\n",
    "        pair = (game.id, dev_id)\n",
    "        if pair in existing_pairs:\n",
    "            continue  # já existe, pula\n",
    "\n",
    "        existing_pairs.add(pair)  # marcar como já incluído\n",
    "        batch.append({\"game_id\": game.id, \"developer_id\": dev_id})\n",
    "\n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            session.execute(sqlalchemy.insert(association_table), batch)\n",
    "            total_inserted += len(batch)\n",
    "            batch.clear()\n",
    "\n",
    "# inserir o último batch\n",
    "if batch:\n",
    "    session.execute(sqlalchemy.insert(association_table), batch)\n",
    "    total_inserted += len(batch)\n",
    "    batch.clear()\n",
    "\n",
    "# commit\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d331f40",
   "metadata": {},
   "source": [
    "#### 3.8.2 Vinculando Jogos e Publicadores\n",
    "\n",
    "A vinculação entre jogos e publicadores segue exatamente o mesmo procedimento descrito na seção anterior (Games–Developers). Aqui, novamente estamos lidando com uma relação muitos-para-muitos (M:N), representada pela tabela de associação `game_publisher`.\n",
    "\n",
    "Como este processo é estruturalmente igual ao da vinculação com desenvolvedores, apresentamos aqui apenas esta explicação concisa, mantendo o código como documentação operacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a6540fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link publishers to games\n",
    "association_table = Game.__table__.metadata.tables[\"game_publisher\"]\n",
    "\n",
    "# 1. Carregar all publishers e games\n",
    "publishers = {p.id: p for p in session.query(Publisher).all()}\n",
    "games = {g.app_id: g for g in session.query(Game).all()}\n",
    "\n",
    "# 2. Criar tracking para evitar duplicações\n",
    "existing_pairs = set()   # (game_id, publisher_id)\n",
    "\n",
    "# Também é útil carregar os pares já existentes no banco:\n",
    "rows = session.execute(association_table.select())\n",
    "for game_id, publisher_id in rows:\n",
    "    existing_pairs.add((game_id, publisher_id))\n",
    "\n",
    "batch = []\n",
    "total_inserted = 0\n",
    "\n",
    "# 3. Processar dataset\n",
    "for row in games_dataset.itertuples():\n",
    "    game = games.get(row.appid)\n",
    "    if not game or not isinstance(row.publishers, list):\n",
    "        continue\n",
    "\n",
    "    for pub_id in row.publishers:\n",
    "        if pub_id not in publishers:\n",
    "            continue\n",
    "\n",
    "        pair = (game.id, pub_id)\n",
    "        if pair in existing_pairs:\n",
    "            continue  # já existe, pula\n",
    "\n",
    "        existing_pairs.add(pair)  # marcar como já incluído\n",
    "        batch.append({\"game_id\": game.id, \"publisher_id\": pub_id})\n",
    "\n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            session.execute(sqlalchemy.insert(association_table), batch)\n",
    "            total_inserted += len(batch)\n",
    "            batch.clear()\n",
    "\n",
    "# 4. Inserir último batch\n",
    "if batch:\n",
    "    session.execute(sqlalchemy.insert(association_table), batch)\n",
    "    total_inserted += len(batch)\n",
    "    batch.clear()\n",
    "\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da3ec3",
   "metadata": {},
   "source": [
    "#### 3.8.3 Vinculando Jogos e Categorias\n",
    "\n",
    "Vincular jogos com categorias segue um procedimento muito semelhante aos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ac3a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_table = Game.__table__.metadata.tables[\"game_category\"]\n",
    "\n",
    "# 1. Carregar all categories e games\n",
    "categories = {c.id: c for c in session.query(Category).all()}\n",
    "games = {g.app_id: g for g in session.query(Game).all()}\n",
    "\n",
    "# 2. Criar tracking para evitar duplicações\n",
    "existing_pairs = set()   # (game_id, category_id)\n",
    "\n",
    "# Também é útil carregar os pares já existentes no banco:\n",
    "rows = session.execute(association_table.select())\n",
    "for game_id, category_id in rows:\n",
    "    existing_pairs.add((game_id, category_id))\n",
    "\n",
    "batch = []\n",
    "total_inserted = 0\n",
    "\n",
    "# 3. Processar dataset\n",
    "for row in games_dataset.itertuples():\n",
    "    game = games.get(row.appid)\n",
    "    if not game or not isinstance(row.categories, list):\n",
    "        continue\n",
    "\n",
    "    for cat_id in row.categories:\n",
    "        if cat_id not in categories:\n",
    "            continue\n",
    "        \n",
    "        pair = (game.id, cat_id)\n",
    "        if pair in existing_pairs:\n",
    "            continue  # já existe, pula\n",
    "\n",
    "        existing_pairs.add(pair)  # marcar como já incluído\n",
    "        batch.append({\"game_id\": game.id, \"category_id\": cat_id})\n",
    "        \n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            session.execute(sqlalchemy.insert(association_table), batch)\n",
    "            total_inserted += len(batch)\n",
    "            batch.clear()\n",
    "\n",
    "# 4. Inserir último batch\n",
    "if batch:\n",
    "    session.execute(sqlalchemy.insert(association_table), batch)\n",
    "    total_inserted += len(batch)\n",
    "    batch.clear()\n",
    "\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236ea3e",
   "metadata": {},
   "source": [
    "#### 3.8.4 Vinculando Jogos e Gêneros\n",
    "\n",
    "Vincular jogos com gêneros segue um procedimento muito semelhante aos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78bbbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_table = Game.__table__.metadata.tables[\"game_genre\"]\n",
    "\n",
    "# 1. Carregar all genres e games\n",
    "genres = {g.id: g for g in session.query(Genre).all()}\n",
    "games = {g.app_id: g for g in session.query(Game).all()}\n",
    "\n",
    "existing_pairs = set()   # (game_id, genre_id)\n",
    "\n",
    "rows = session.execute(association_table.select())\n",
    "for game_id, genre_id in rows:\n",
    "    existing_pairs.add((game_id, genre_id))\n",
    "\n",
    "batch = []\n",
    "total_inserted = 0\n",
    "\n",
    "for row in games_dataset.itertuples():\n",
    "    game = games.get(row.appid)\n",
    "    if not game or not isinstance(row.genres, list):\n",
    "        continue\n",
    "    \n",
    "    for genre_id in row.genres:\n",
    "        if genre_id not in genres:\n",
    "            continue\n",
    "        \n",
    "        pair = (game.id, genre_id)\n",
    "        if pair in existing_pairs:\n",
    "            continue  # já existe, pula\n",
    "        \n",
    "        existing_pairs.add(pair)  # marcar como já incluído\n",
    "        batch.append({\"game_id\": game.id, \"genre_id\": genre_id})\n",
    "        \n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            session.execute(sqlalchemy.insert(association_table), batch)\n",
    "            total_inserted += len(batch)\n",
    "            batch.clear()\n",
    "\n",
    "if batch:\n",
    "    session.execute(sqlalchemy.insert(association_table), batch)\n",
    "    total_inserted += len(batch)\n",
    "    batch.clear()\n",
    "\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a7fd57",
   "metadata": {},
   "source": [
    "#### 3.8.5 Vinculando Jogos e Tags\n",
    "\n",
    "Vincular jogos com tags segue um procedimento muito semelhante aos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea819f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_table = Game.__table__.metadata.tables[\"game_tag\"]\n",
    "\n",
    "# 1. Carregar all tags e games\n",
    "tags = {t.id: t for t in session.query(Tag).all()}\n",
    "games = {g.app_id: g for g in session.query(Game).all()}\n",
    "\n",
    "existing_pairs = set()   # (game_id, tag_id)\n",
    "\n",
    "rows = session.execute(association_table.select())\n",
    "for game_id, tag_id in rows:\n",
    "    existing_pairs.add((game_id, tag_id))\n",
    "\n",
    "batch = []\n",
    "total_inserted = 0\n",
    "\n",
    "for row in games_dataset.itertuples():\n",
    "    game = games.get(row.appid)\n",
    "    if not game or not isinstance(row.tags, list):\n",
    "        continue\n",
    "    \n",
    "    for tag_id in row.tags:\n",
    "        if tag_id not in tags:\n",
    "            continue\n",
    "        \n",
    "        pair = (game.id, tag_id)\n",
    "        if pair in existing_pairs:\n",
    "            continue  # já existe, pula\n",
    "        \n",
    "        existing_pairs.add(pair)  # marcar como já incluído\n",
    "        batch.append({\"game_id\": game.id, \"tag_id\": tag_id})\n",
    "        \n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            session.execute(sqlalchemy.insert(association_table), batch)\n",
    "            total_inserted += len(batch)\n",
    "            batch.clear()\n",
    "\n",
    "if batch:\n",
    "    session.execute(sqlalchemy.insert(association_table), batch)\n",
    "    total_inserted += len(batch)\n",
    "    batch.clear()\n",
    "\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd3b38",
   "metadata": {},
   "source": [
    "#### 3.8.5 Vinculando Jogos e Linguas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62fc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_table = Game.__table__.metadata.tables[\"game_language\"]\n",
    "\n",
    "# 1. Carregar all languages e games\n",
    "languages = {l.id: l for l in session.query(Language).all()}\n",
    "games = {g.app_id: g for g in session.query(Game).all()}\n",
    "\n",
    "existing_pairs = set()   # (game_id, language_id)\n",
    "\n",
    "rows = session.execute(association_table.select())\n",
    "for game_id, language_id in rows:\n",
    "    existing_pairs.add((game_id, language_id))\n",
    "\n",
    "batch = []\n",
    "total_inserted = 0\n",
    "\n",
    "for row in games_dataset.itertuples():\n",
    "    game = games.get(row.appid)\n",
    "    if not game or not isinstance(row.supported_languages, list):\n",
    "        continue\n",
    "    \n",
    "    for language_id in row.supported_languages:\n",
    "        if language_id not in languages:\n",
    "            continue\n",
    "        \n",
    "        pair = (game.id, language_id)\n",
    "        if pair in existing_pairs:\n",
    "            continue  # já existe, pula\n",
    "        \n",
    "        existing_pairs.add(pair)  # marcar como já incluído\n",
    "        batch.append({\"game_id\": game.id, \"language_id\": language_id})\n",
    "        \n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            session.execute(sqlalchemy.insert(association_table), batch)\n",
    "            total_inserted += len(batch)\n",
    "            batch.clear()\n",
    "\n",
    "if batch:\n",
    "    session.execute(sqlalchemy.insert(association_table), batch)\n",
    "    total_inserted += len(batch)\n",
    "    batch.clear()\n",
    "\n",
    "session.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-steam-games-ipUGnf44",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
